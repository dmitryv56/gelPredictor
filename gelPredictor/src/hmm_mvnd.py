#!/usr/bin/env python3

""" The class in this module is HMMmvndemis (Hidden Markov Model for multivariate normal distributed emission).
It implements HMM with emission probabilities determined by multivariate normal distributions and based on
sklearn.hmm.GaussianHMM class (see https://scikit-learn.sourceforge.net/stable/modules/hmm.html).

The HMM is a generative probabilistic model, in which a seguence of observable X multivariate variable is generated by
a sequence of internal hidden states Z. The hidden states cannot be observed directly. The transitions between hidden
states are assumed to have the form of a (first-order) Markov chain. They can be specified by the start probability
vector P and a transition probability matrix A. The emission probability of an observable in our case are multivariate
normal distributed (Gaussian) with parameters TETA(i) (means(i)(vector) and covariance matrix(i) are estimated along
training dataset, where i - is an state index.
    The HMM is completely determined by P,A, TETA(i) , i = 0,1, number_of_states-1."""

import sys

from pathlib import Path
from hmmlearn.hmm import GaussianHMM
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

from src.pca import PCA_

PATH_TO_CSV="~/LaLaguna/gelPredictor/dataset_Repository/CAISO_Load_01012020_24042023.csv"

class HMMmvndemis():
    pass
    def __init__(self,y:np.array=None, dt:np.array = None, n_features:int=16, n_states:int=3, log_folder:Path = None ,
                 title:str="CaISO"):
        if y is None:
            sys.exit(-1)
        self.n_features=n_features
        self.n_states = n_states
        (n,)=y.shape
        if n<self.n_features:
            sys.exit(-2)
        self.n_samples=int(n/self.n_features)
        self.X=y[:self.n_samples * self.n_features].reshape(self.n_samples, self.n_features)
        self.log_folder=log_folder
        self.title = title
        if dt is None:
            self.dt=np.array([str(i) for i in range( self.n_samples * self.n_features)])
        else:
            self.dt=dt
        self.y_mean = np.zeros(self.n_samples, dtype=float)
        self.y_std = np.zeros(self.n_samples, dtype=float)
        self.y_min = np.zeros(self.n_samples, dtype=float)
        self.y_max = np.zeros(self.n_samples, dtype=float)
        self.obs_simple_stat()
        self.obs_norm()

        self.clusters = DataCluster(num_classes=self.n_states)
        n_iter, n_features_in, self.inertia_, self.state_sequence, self.means = self.clusters.fit(X=self.X)
        self.covar = self.covar_estimation()
        self.states, self.state_counts = np.unique(self.state_sequence, return_counts= True)
        self.pai = None
        self.transition = None
        self.model = None



    def obs_simple_stat(self):
        """ The observations -simple statistics """

        for i in range(self.n_samples):
            self.y_mean[i]=self.X[i,:].mean()
            self.y_std[i] = self.X[i, :].std()
            self.y_min[i] = self.X[i, :].min()
            self.y_max[i] = self.X[i, :].max()
        #     charts & logs
        (n,m)=self.X.shape

        file_stats = Path("{}_per_segment_statistics".format(self.title)).with_suffix(".txt")
        with open(file_stats, 'w') as fout:
            msg ="{:^5s} {:^30s} {:<12s} {:<12s} {:<12s} {:<12s}\n".format(" ##  ","Timestamp","Mean","Std",
                                                                                       "Min","Max")
            fout.write(msg)
            for i in range(n):
                msg = "{:>5d} {:<30s} {:<12.6e} {:<12.6e} {:<12.6e} {:<12.6e}\n".format(i,self.dt[i*m], \
                        self.y_mean[i],self.y_std[i], self.y_min[i], self.y_max[i])
                fout.write(msg)
        # Plot the sampled data
        plt.rcParams["figure.figsize"] = [7.50, 3.50]
        plt.rcParams["figure.autolayout"] = True
        x=np.array([i for i in range(n)])
        plt.plot(x, self.y_mean, label ="average daily power ", alpha=0.7)
        plt.plot(x, self.y_std,  label ="std daily power",  alpha=0.7)
        plt.plot(x,  self.y_min, label = "min daily power", alpha=0.7)
        plt.plot(x,  self.y_max, label = "max daily power", alpha=0.7)
        plt.legend(loc='best')
        plt.show()
        plt.savefig("{}_Statistics_per_Day.png".format(self.title))
        plt.close("all")
        return

    def obs_norm(self):
        """ The observations in the 2D matrix - normalization (-1.0 ...+1.0) """

        self.minmin, self.maxmax = self.X.min(), self.X.max()

        self.X=(self.X -self.minmin)/(self.maxmax-self.minmin)


    def pai_fit(self):
        """ The initial probabilities (Pai) - maximum likelihood estimation (MLE) """

        (n,)=self.state_counts.shape
        if (n<self.n_states):
            print("Missing states - exit")
            sys.exit(-3)

        sum_ = self.state_counts.sum()
        self.pai=np.array([float(self.state_counts[i]/sum_) for i in range(self.n_states)], dtype=float)
        return

    def transition_fit(self):
        """ The transition matrix - MLE"""

        if len(self.state_sequence) == 0 or len(self.states) == 0:
            # logger.error("{} invalid arguments".format(transitionsMLE.__name__))
            return None
        if self.state_counts[self.state_sequence[-1]] == 1 :
            # Note: If some state appears only once one as last item in seqiuence then this state will loss.
            sys.exit(-4)
            # Denominators are counts of state occurence along sequence without last item.
        _, denominators = np.unique(self.state_sequence[:-1], return_counts=True)
        # Note: If some state appears only once one as last item in seqiuence then this state will loss.

        self.transition = np.zeros((len(self.states), len(self.states)), dtype=float)

        for statei in self.states:
            denominator = denominators[statei]
            msg = "State {} : ".format(statei)
            for statej in self.states:
                nominator = 0
                for k in range(len(self.state_sequence) - 1):
                    if self.state_sequence[k] == statei and self.state_sequence[k + 1] == statej:
                        nominator += 1
                self.transition[statei][statej] = round(float(nominator) / float(denominator), 6)
                msg = msg + "{} ".format(self.transition[statei][statej])
            message = f"""{msg}"""
            # logger.info(message)
        return

    def covar_estimation(self)->np.array:
        """ The covariation matrix - MLE.
        (N,M)=X.shape
        cov=(X.T * X)/(N-1), M * M -matrix
        """

        x_mean=self.X.mean(0)
        X = self.X - self.X.mean(axis=0,keepdims=True)
        return np.cov(X.T)


    def fit(self):

        self.pai_fit()
        self.transition_fit()

        self.model = GaussianHMM(n_components=self.n_states, covariance_type="tied")
        self.model.n_features =self.n_features
        # model.transmat=self.transition
        # model.startprob=self.pai

        self.model.means_=self.means
        self.model.covars_ = self.covar

        self.model.fit(self.X)
        vitterbi1= self.model.decode(self.X)
        self.vitterbi = self.model.predict(self.X)
        plt.rcParams["figure.figsize"] = [7.50, 3.50]
        plt.rcParams["figure.autolayout"] = True
        x = np.array([i for i in range(self.n_samples)])
        plt.plot(x, self.vitterbi, label="Decoded sequence states", alpha=0.7)
        plt.plot(x, self.state_sequence, label="Sequencr states", alpha=0.7)

        plt.legend(loc='best')
        plt.show()
        plt.savefig("{}_{}_State_Decoded_States.png".format(self.title,self.n_states))
        plt.close("all")


    def chartTransitions(self,X:np.array):
        """ """
        (n_samples,n_components) = X.shape
        # plot model states over time
        fig, ax = plt.subplots()
        ax.plot(self.state_sequence, self.vitterbi)
        ax.set_title('States compared to generated')
        ax.set_xlabel('Generated State')
        ax.set_ylabel('Recovered State')
        fig.show()
        fig.savefig("{}_Generated_Recovered_{}_States.png".format(self.title,self.n_states))

        # plot the transition matrix
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 5))
        ax1.imshow(self.transition, aspect='auto', cmap='spring')
        ax1.set_title('Generated Transition Matrix')
        ax2.imshow(self.transition, aspect='auto', cmap='spring')
        ax2.set_title('Recovered Transition Matrix')
        for ax in (ax1, ax2):
            ax.set_xlabel('State To')
            ax.set_ylabel('State From')

        fig.tight_layout()
        fig.show()
        fig.savefig("{}_Generated_Recovered_Transitions_{}_States.png".format(self.title,self.n_states))

        # Plot the sampled data
        fig, ax = plt.subplots()
        ax.plot(X[:, 0], X[:, 1], ".-", label="observations", ms=6,
                mfc="orange", alpha=0.7)

        vtrb_states, vtrb_counts = np.unique(self.vitterbi,return_counts=True)
        (n_states,)=vtrb_states.shape
        mean = np.zeros((n_states, n_components), dtype=float)
        for i in range(n_samples):
            st=self.vitterbi[i]
            for j in range(n_components):
                mean[st][j]=mean[st][j] + X[i][j]
        for i in range(n_states) :
            for j in range(n_components):
                mean[i][j]=mean[i][j]/vtrb_counts[i]
        # Indicate the component numbers
        for i, m in enumerate(mean):
            ax.text(m[0], m[1], 'State %i' % (i + 1),
                    size=17, horizontalalignment='center',
                    bbox=dict(alpha=.7, facecolor='w'))
        ax.legend(loc='best')
        fig.show()
        fig.savefig("{}_Observations_{}_States.png".format(self.title,self.n_states))



class DataCluster():

    def __init__(self, num_classes:int = 3, log_folder:Path=None):
        pass
        self.num_classes =num_classes
        self.cluster_labels = None
        self.cluster_centers = None


    def fit(self, X:np.array =None)->(int, int, float, np.array, np.array ):
        pass
        (self.n_samples, self.n_features) =X.shape

        kmeans = KMeans(n_clusters=self.num_classes, init='k-means++', random_state=0, n_init=1).fit(X)
        self.cluster_labels=kmeans.labels_
        self.cluster_centers = kmeans.cluster_centers_
        return kmeans.n_iter_, kmeans.n_features_in_, kmeans.inertia_, kmeans.labels_, kmeans.cluster_centers_




if __name__ == "__main__":
    df = pd.read_csv(PATH_TO_CSV)
    y = df["Load"].values
    dt = df["Date Time"].values
    model = HMMmvndemis(y=y, n_features=288, n_states=2, log_folder = None )
    model.fit()
    print(model.y_min, model.y_max, model.y_mean, model.y_std)

    print(model.state_sequence)

    print(model.means)

    pca=PCA_(n_components=2,log_folder=None,title="2comp")
    pca.fit(X=model.X)
    pca.rpt2log()
    model.chartTransitions(pca.X_pca)